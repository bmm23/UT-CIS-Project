{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "cookies = {\n",
    "    'csrftoken-studentfinancials.mytuitionbill-Prod': '6kiZx7OERXh7GFHH9iUM0L9xvHiyYj9qKrJOgkOGVpZ4ZGZ3l5JuzhI93not7nXw',\n",
    "    'ut_persist': '1879484608.47873.0000',\n",
    "    '_shibsession_64656661756c7468747470733a2f2f75746469726563742e7574657861732e6564752f73686962626f6c657468': '_94abe11b38ab22e5942ef50d02eb1572',\n",
    "    'SC': 'AQEBBwID6gIQRjg0MDZENTA4QjIxNDRBMgYkdVR6ZWo5RlJ1a0xEajNFT2p5Z0hMVkZEWTVmRzZ6VFl3MHpKBAoxNjQxOTUwOTgxBQ8yMDkuMTY2LjEyMi4yMDEDB2JtbTM4ODYKAVkIgBIx4qBKFdcUS0kqCgKswgUoZPdoE+ms2ZEM764Sl4RNRjqA+5YR8FGQr0VwQ/qXu93foM9bTwb9C3JPzOWpyTDjduSqsMYgVJYnCxDCsYGu/7JmwMZUCtG9OFQICtgFguqiLW4VlDZVW+ZIUX1s35DobIEkD9OmtKLgd21xyoe7',\n",
    "}\n",
    "\n",
    "\n",
    "headers = {\n",
    "    'Connection': 'keep-alive',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'sec-ch-ua':\n",
    "    '\" Not A;Brand\";v=\"99\", \"Chromium\";v=\"96\", \"Google Chrome\";v=\"96\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent':\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',\n",
    "    'Accept':\n",
    "    'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-Mode': 'navigate',\n",
    "    'Sec-Fetch-User': '?1',\n",
    "    'Sec-Fetch-Dest': 'document',\n",
    "    'Referer':\n",
    "    'https://utdirect.utexas.edu/ctl/ecis/results/view_results.WBX?s_me_cis_id=2012232265000001',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'If-Modified-Since': 'Tue, 11 Jan 2022 15:33:19 CST',\n",
    "}\n",
    "\n",
    "params = (('s_me_cis_id', '2012232265000001'), )\n",
    "\n",
    "response = requests.get(\n",
    "    'https://utdirect.utexas.edu/ctl/ecis/results/view_results.WBX',\n",
    "    headers=headers,\n",
    "    params=params,\n",
    "    cookies=cookies)\n",
    "\n",
    "#NB. Original query string below. It seems impossible to parse and\n",
    "#reproduce query strings 100% accurately so the one below is given\n",
    "#in case the reproduced version is not \"correct\".\n",
    "# response = requests.get('https://utdirect.utexas.edu/ctl/ecis/results/view_results.WBX?s_me_cis_id=2012232265000001', headers=headers, cookies=cookies)\n",
    "#NB. Original query string below. It seems impossible to parse and\n",
    "#reproduce query strings 100% accurately so the one below is given\n",
    "#in case the reproduced version is not \"correct\".\n",
    "# response = requests.get('https://utdirect.utexas.edu/ctl/ecis/results/view_results.WBX?s_me_cis_id=2011241555000001', headers=headers, cookies=cookies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def spaceRemover(string):\n",
    "    return ' '.join(string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://utdirect.utexas.edu/ctl/ecis/results/view_results.WBX?s_me_cis_id=2012232265000001'\n",
    "uniqueID = ''.join(re.findall(r'\\d+',link))\n",
    "\n",
    "try:\n",
    "    response = requests.get(link, headers=headers, cookies=cookies)\n",
    "except:\n",
    "    print('cookie timed out')\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportScrape(link):\n",
    "    try:\n",
    "        response = requests.get(link, headers=headers, cookies=cookies)\n",
    "    except:\n",
    "        return ('cookie timed out, refresh')\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    fieldSet = soup.find('fieldset')\n",
    "    detailsList = [div.contents[1] for div in fieldSet.find_all('div')]\n",
    "\n",
    "    instructorName = spaceRemover(detailsList[0])\n",
    "    courseID = spaceRemover(detailsList[1])\n",
    "    organization = spaceRemover(detailsList[2])\n",
    "    college = spaceRemover(detailsList[3])\n",
    "    semester = spaceRemover(detailsList[4])\n",
    "    enrolledStudents = spaceRemover(detailsList[5])\n",
    "    formsReturned = spaceRemover(fieldSet.find_all('div')[-1].contents[2])\n",
    "\n",
    "    tableZeroAnswers = {'Instructor':instructorName,'Course ID':courseID, 'Organization':organization,'College/School':college,'Semester':semester,'Grade-eligible enrollment':enrolledStudents,'Number of survey forms returns':formsReturned}\n",
    "\n",
    "    tableOne = soup.find_all('table')[0]\n",
    "    tableOneAnswers = {}\n",
    "    tableOneKey = ['Strongly Disagree','Disagree','Neutral','Agree','Strongly Agree','Number of Respondents','Average','Organization Average', 'College/School Average', 'University Average']\n",
    "\n",
    "    tableOneAnswers['The course was well organized.']  = dict(zip(tableOneKey,[td.string.split(' ')[0] for td in tableOne.find_all('td')[1:11]]))\n",
    "    tableOneAnswers['The instructor communicated information effectively.'] = dict(zip(tableOneKey,[td.string.split(' ')[0] for td in tableOne.find_all('td')[12:22]]))\n",
    "    tableOneAnswers['The instructor showed interest in the progress of students.'] = dict(zip(tableOneKey,[td.string.split(' ')[0] for td in tableOne.find_all('td')[23:33]]))\n",
    "    tableOneAnswers['The tests/assignments were usually graded and returned promptly.']  = dict(zip(tableOneKey,[td.string.split(' ')[0] for td in tableOne.find_all('td')[34:44]]))\n",
    "    tableOneAnswers['The instructor made me feel free to ask questions, disagree, and express my ideas.']  = dict(zip(tableOneKey,[td.string.split(' ')[0] for td in tableOne.find_all('td')[45:55]]))\n",
    "    tableOneAnswers['At this point in time, I feel that this course will be (or has already been) of value to me.']   = dict(zip(tableOneKey,[td.string.split(' ')[0] for td in tableOne.find_all('td')[56:66]]))\n",
    "\n",
    "    tableTwo  = soup.find_all('table')[1]\n",
    "    tableTwoAnswers = {}\n",
    "    tableTwoKey = ['Very Unsatisfactory','Unsatisfactory','Satisfactory','Very Good','Excellent','Number of respondents','Average','Organization Average','College/School Average','University Average']\n",
    "\n",
    "    tableTwoAnswers['Overall, this instructor was'] = dict(zip(tableTwoKey,[td.string.split(' ')[0] for td in tableTwo.find_all('td')[1:11]]))\n",
    "    tableTwoAnswers['Overall, this course was'] = dict(zip(tableTwoKey,[td.string.split(' ')[0] for td in tableTwo.find_all('td')[12:22]]))\n",
    "\n",
    "    tableThree = soup.find_all('table')[2]\n",
    "    tableThreeAnswers = {}\n",
    "    tableThreeKey = ['Excessive', 'High','Average','Light','Insufficient','Number of respondents','Average',\t'Organization Average','College/School Average','University Average']\n",
    "\n",
    "    tableThreeAnswers['In my opinion, the workload in this course was'] = dict(zip(tableThreeKey,[td.string.split(' ')[0] for td in tableThree.find_all('td')[1:11]]))\n",
    "\n",
    "\n",
    "    finalAnswers = [tableZeroAnswers, tableOneAnswers, tableTwoAnswers, tableThreeAnswers]\n",
    "\n",
    "    return finalAnswers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportData(data):\n",
    "    try:\n",
    "        to_unicode = unicode\n",
    "    except NameError:\n",
    "        to_unicode = str\n",
    "    data = reportScrape(link)\n",
    "\n",
    "\n",
    "    with io.open('{}.json'.format(uniqueID), 'w', encoding='utf8') as outfile:\n",
    "        str_ = json.dumps(data,\n",
    "                        indent=4, sort_keys=True,\n",
    "                        separators=(',', ': '), ensure_ascii=False)\n",
    "        outfile.write(to_unicode(str_))\n",
    "def writeStop():\n",
    "    with open('stoppplace.txt', 'r') as f:\n",
    "        lastPlace = int(f.read())\n",
    "    with open('stoppplace.txt','w') as f:\n",
    "        f.write(str(lastPlace + 1))\n",
    "\n",
    "def currentPos():\n",
    "    with open('stoppplace.txt', 'r') as f:\n",
    "        lastPlace = int(f.read())\n",
    "    return lastPlace\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1c77693401acacf8514caa54e61c2fc37284d431992bf60671775e5dab4ab60"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
